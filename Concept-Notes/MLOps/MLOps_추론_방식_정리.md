

---

# 추론(Inference) 심화 정리

### 1) 추론이란?

* **정의:** 학습(Training)으로 얻은 모델을 이용해 **새 입력에 대한 예측을 계산**하는 과정.
* **학습 vs 추론**

  * 학습: 가중치를 바꾸며 규칙을 “배움”.
  * 추론: 가중치는 고정, 계산만 해서 “답을 냄”.
* **SLA 관점의 세 축(항상 트레이드오프)**

  * **지연시간**(p95/p99 목표), **신선도**(얼마나 최신 데이터 반영?), **비용**(GPU/서버 수).

---

## 2) 서비스 요구에 따라 달라지는 설계 레버

* **실시간성:** 즉답 필요(챗봇/검색/결제) vs 대량 사전계산(추천/리포트).
* **개인화 강도:** 유저별·컨텍스트별로 깊이 반영할수록 온라인 계산이 늘어남.
* **트래픽 패턴:** 피크가 큰가? 폭발적 증가에 확장 가능한가?
* **데이터 접근:** 요청 시점 조인? 사전 집계? **Online Feature Store** 사용?
* **설명가능성/위험:** 중요한 결정(여신심사)은 보수적 전략+로그/리플레이 필요.
* **비용:** GPU/ANN 서버/캐시·스토리지의 균형.

---

## 3) 핵심 추론 패턴 (구조, 장단점, 언제 쓰나)

### A. **온라인 동기식 단일 모델 API**

* **구조:** `클라이언트 → /predict → (전처리) → 모델 → (후처리) → 응답`
* **장점:** 단순, 변경 쉬움.
* **단점:** 모델이 무겁거나 피처 조인이 많으면 p95 초과 위험.
* **팁:** 마이크로배칭(서버 내부에서 수ms 묶어 GPU 효율↑), 고정형 전처리 파이프라인.

---

### B. **2단계 추천(가Candidate → Ranker → (Re-ranker))**

* **구조:**

  1. **후보생성**: 대규모 풀에서 수천개 빠르게 뽑기(ANN/벡터검색/규칙)
  2. **랭커**: 수백\~수천 후보에 고성능 모델 적용
  3. (옵션) **리랭커**: 직전 컨텍스트로 마지막 정렬(탭/시간/기기)
* **장점:** 대규모에서 **지연시간과 품질 균형**에 최적.
* **단점:** 서비스/특징/모델이 여러 개라 운영 복잡.
* **언제:** OTT/커머스/게임 추천(LoL 추천도 이 구조가 표준).

---

### C. **계단식(cascading)/얼리-엑싯**

* **구조:** 싼 모델 → 기준 통과 못하면 즉시 종료, 일부만 비싼 모델 통과.
* **장점:** **비용↓, 평균 지연시간↓**.
* **단점:** 임계치 튜닝 난이도, 공정성/커버리지 주의.
* **언제:** 스팸/부정 사용 탐지, 검색 랭킹 1차 필터.

---

### D. **오프라인(배치) 추론**

* **구조:** 스케줄러가 주기적으로 대량 예측 → DB/캐시에 저장 → 실시간엔 **읽기만**.
* **장점:** 대량처리 효율 최고, **요청시 지연≈캐시 히트**.
* **단점:** **콜드스타트/신선도** 문제(신규/급변 상황 반영 느림).
* **언제:** 데일리 추천/점수, 리스크 스코어, 리포트.

---

### E. **하이브리드(오프라인 + 온라인 보정)**

* **구조:** 기본은 전날 예측(배치) 사용 + 실시간 신호(최근 클릭/접속)로 **경량 보정**.
* **장점:** **속도와 신선도 모두 확보**.
* **단점:** 이중 경로 동기화·검증 필요.
* **언제:** 대부분의 대규모 추천/랭킹 서비스 베스트 프랙티스.

---

### F. **스트리밍/니어라인 추론**

* **구조:** 이벤트 스트림(Kafka 등) → 피처 업데이트/간이모델 → 수초 내 반영.
* **장점:** 신선도↑, 완전 실시간보다 비용/복잡도↓.
* **단점:** 스트림 인프라, 정확한 중복/순서 보장 설계 필요.
* **언제:** 실시간 반응 중요하지만 완전 동기식이 부담일 때.

---

### G. **캐시 패턴(결과/피처/임베딩 캐시)**

* **구조:** (유저,쿼리) 키로 Redis/메모리에 결과 저장(TTL). 피처/임베딩도 캐싱.
* **장점:** **지연시간↓, 비용↓**.
* **단점:** **무효화 전략**(TTL/이벤트 기반) 설계 없으면 품질 저하.
* **언제:** 반복 요청이 많고 즉시성 중요한 곳.

---

### H. **병렬/팬아웃-팬인 마이크로서비스**

* **구조:** 여러 모델을 **병렬** 호출 → 집계(가중합/투표/머지).
* **장점:** 다양성↑, 강건성↑.
* **단점:** 네트워크 지연 합산, **느린 놈 기다리기** 문제 → 타임아웃/부분결과 필요.
* **언제:** 앙상블, 멀티 시그널 결합.

---

### I. **엣지/온디바이스 추론**

* **장점:** 네트워크 없이 초저지연, 개인정보 로컬 처리.
* **단점:** 모델 경량화(양자화/프루닝), 업데이트/관측 난이도.
* **언제:** 모바일/IoT, 입력 프라이버시 민감.

---

### J. **비동기 추론(잡 큐)**

* **구조:** 요청 수락 → 잡 큐에 넣고 **나중에 결과 통지/폴링**.
* **장점:** 초고비용·장기 작업 안정 처리, 급증 트래픽 흡수.
* **단점:** 사용자 경험 설계 필요(대기, 알림).
* **언제:** 대용량 요약/영상처리/파이프라인 배치.

---

## 4) 피처/데이터 경로 패턴

* **요청시 조인(request-time join):** 최대 신선도, 지연↑ → Online Feature Store 권장.
* **사전 집계(precompute):** 빠름, 신선도↓ → 배치/니어라인로 보완.
* **임베딩 흐름:** 오프라인 임베딩 생성 → 온라인에 캐시/ANN서버. 유저 최신 임베딩은 이벤트로 갱신.

---

## 5) 운영 팁(실무에서 진짜 중요한 것들)

**성능·비용**

* **서버 마이크로배칭**(수ms 단위)으로 GPU 활용 극대화.
* **모델 경량화:** distillation/quantization/텐서RT/온nx 최적화.
* **단계별 SLA 분배:** 예) 전체 250ms → 후보 30ms, 랭커 150ms, 리랭커 40ms, 마진 30ms.

**신뢰성**

* **타임아웃/서킷브레이커:** 느린 서브모델은 스킵하고 **폴백**으로 degrade.
* **폴백 전략:** 마지막 성공 결과, 규칙기반, 인기 상위 N.

**관측성**

* **스팬 트레이싱:** 전처리/모델/후처리 **구간별 지연** 분해.
* **모델 헬스:** 입력분포, 피처 누락율, 스코어 분포 드리프트 알림.
* **온라인 지표:** CTR/전환·오류율·p95/p99.

**릴리즈**

* **카나리/그린블루/셰도우 테스트**로 안전 배포.
* **AB 실험**과 **셰도우**를 분리 이해: 셰도우=유저에 안 보임, AB=유저 일부에 보임.

---

## 6) 언제 어떤 패턴을 고를까? (빠른 체크리스트)

* **즉답 필수(≤300ms)**: 온라인 단일 or 2단계(+캐시).
* **대상 큼(수천만)·비용 민감**: 오프라인/하이브리드.
* **신규유저/급변 대응**: 하이브리드 or 스트리밍.
* **모델 다수 결합**: 병렬 팬아웃-팬인 + 타임아웃/폴백.
* **프라이버시/오프라인 디바이스**: 엣지 추론.

---

