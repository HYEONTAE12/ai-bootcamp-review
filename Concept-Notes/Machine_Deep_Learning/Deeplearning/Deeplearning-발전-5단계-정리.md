
---

# 🧠 딥러닝 발전 5단계 정리

---

## 🚩 전체 개요

딥러닝의 발전은
**“사람이 규칙을 직접 만드는 시대(SW1.0)” → “기계가 스스로 학습하는 시대(SW2.0)” → “문맥만으로 학습하는 시대(SW3.0)”**
로 발전해왔다.

이 과정은 곧 **“사람에서 기계로의 전환”**,
그리고 **“명시적 규칙에서 암묵적 학습으로의 진화”**를 의미한다.

---

## 🧩 SW1.0 — Rule-based Programming

### 📖 본문 요약

* 사람이 직접 규칙을 입력하는 방식.
* 기계는 스스로 학습하지 않고, 사람이 정의한 조건만 수행한다.
* 예시:

  ```text
  귀의 길이가 10cm 이하이면 고양이다.
  코 색깔이 검정색이면 고양이다.
  ```

### 💡 복습 핵심

| 구분     | 내용                     |
| ------ | ---------------------- |
| 특징     | 규칙을 사람이 직접 입력          |
| 장점     | 단순하고 예측 가능함            |
| 단점     | 새로운 데이터나 상황에 적응 불가     |
| 한 줄 요약 | **“사람이 모든 조건을 정의한다.”** |

**문제 복습:**

> ❓ SW1.0 방식의 한계는?
> ✅ 기계가 스스로 특징을 학습하지 못한다.

---

## 🧩 SW1.5 — Conventional Machine Learning

### 📖 본문 요약

* **SW1.0과 SW2.0의 하이브리드.**
* **사람이 특징(feature)을 정의하고**,
  **기계가 그 특징을 이용해 판단(classification)**을 수행한다.
* 예: “귀 길이”, “코 색” 같은 특징은 사람이 정하고,
  어떤 조합이 고양이인지 판단은 모델이 학습.

### 💡 복습 핵심

| 구분     | 내용                      |
| ------ | ----------------------- |
| 특징 정의  | 사람이 수행                  |
| 판단 학습  | 기계가 수행                  |
| 장점     | 규칙기반보다 자동화된 판단 가능       |
| 단점     | 여전히 특징을 사람이 설계해야 함      |
| 한 줄 요약 | **“사람은 특징을, 기계는 판단을.”** |

**문제 복습:**

> ❓ SW1.5의 핵심 구조는?
> ✅ 특징은 사람, 판단은 기계

---

## 🧩 SW2.0 — Deep Learning

### 📖 본문 요약

* 사람이 직접 특징을 정의하지 않고,
  **기계가 스스로 특징을 학습**하는 방식.
* 입력 → 여러 은닉층(hidden layer)을 통해 특징 추출 → 출력
* 모든 연산을 기계가 고안하여 학습한다.

### 💡 복습 핵심

| 구분     | 내용                        |
| ------ | ------------------------- |
| 특징 정의  | 기계가 스스로 수행                |
| 장점     | 사람이 설계하지 않아도 복잡한 패턴 학습 가능 |
| 단점     | 대량의 데이터와 연산 자원이 필요        |
| 한 줄 요약 | **“기계가 스스로 특징을 배운다.”**    |

**문제 복습:**

> ❓ SW2.0의 핵심 전환점은?
> ✅ 특징을 사람이 아닌 기계가 정의하기 시작했다.

---

## 🧩 SW2.0+ — Pretraining & Fine-tuning

### 📖 본문 요약

* 기존 SW2.0의 한계:
  태스크나 클래스가 바뀔 때마다 **새 모델을 다시 학습해야 함.**
* 해결책:
  **Pretraining(사전학습)** + **Fine-tuning(미세조정)**
* Pretraining: 다양한 데이터로 일반적인 특징 학습
* Fine-tuning: 원하는 태스크에 맞게 일부 레이어만 새로 학습

### 💡 복습 핵심

| 구분          | 내용                       |
| ----------- | ------------------------ |
| Pretraining | 여러 클래스에서 일반적인 특징 학습      |
| Fine-tuning | 특정 클래스나 태스크에 맞게 조정       |
| 장점          | 기존 모델 재활용, 데이터 효율적       |
| 한 줄 요약      | **“한 번 배우고 다양하게 응용한다.”** |

**문제 복습:**

> ❓ Fine-tuning의 장점은?
> ✅ 기존 모델을 활용해 새로운 태스크에 빠르게 적응한다.

---

## 🧩 SW3.0 — In-context Learning

### 📖 본문 요약

* **파라미터 업데이트 없이, 프롬프트(문맥)만으로 새로운 테스크 수행.**
* “few-shot / zero-shot” 학습이라고도 불린다.
* 예시: GPT 계열 모델이 “문제-답 예시” 몇 개만 주어도 새로운 문제를 푸는 것.

### 💡 복습 핵심

| 구분     | 내용                         |
| ------ | -------------------------- |
| 특징     | 추가 학습 없이 문맥 기반으로 새로운 문제 해결 |
| 장점     | 빠르고 유연함, 데이터가 없어도 작동 가능    |
| 단점     | 결과가 항상 안정적이지는 않음           |
| 한 줄 요약 | **“문맥으로 배우는 모델.”**         |

**문제 복습:**

> ❓ Fine-tuning과 In-context learning의 차이?
> ✅ Fine-tuning은 파라미터를 업데이트하지만, In-context는 문맥으로만 학습한다.

---

## 🧩 전체 흐름 요약표

| 단계     | 이름                      | 학습 주체   | 특징               | 키워드                  |
| ------ | ----------------------- | ------- | ---------------- | -------------------- |
| SW1.0  | Rule-based              | 사람      | 직접 규칙 정의         | IF-THEN 규칙           |
| SW1.5  | Conventional ML         | 사람 + 기계 | 특징은 사람, 판단은 기계   | feature engineering  |
| SW2.0  | Deep Learning           | 기계      | 특징 추출부터 출력까지 자동화 | end-to-end           |
| SW2.0+ | Pretraining/Fine-tuning | 기계      | 기존 모델 재활용        | transfer learning    |
| SW3.0  | In-context Learning     | 기계      | 문맥을 통해 문제 해결     | few-shot / zero-shot |

---

## 🧭 핵심 문장 요약

> “딥러닝 발전의 흐름은
> **사람이 규칙을 만들던 시대(SW1.0)**에서 →
> **기계가 규칙을 배우는 시대(SW2.0)**를 거쳐 →
> **문맥만으로 문제를 푸는 시대(SW3.0)**로 발전하였다.
>
> 이 변화의 핵심은 **사람에서 기계로의 전환**이다.”

---
