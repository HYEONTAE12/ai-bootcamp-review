
---

# 📘 지도학습(Supervised Learning) 정리

## 1. 회귀 모델 (Regression Model)

* **정의**: 종속변수 $y$가 **연속형 변수**일 때 사용하는 모델
* **목표**: 입력값이 주어졌을 때 출력값(연속값)을 예측

**예시**

* 부모 키 → 자녀 키
* 오늘 기온 → 내일 기온

### 🔹 선형회귀 (Linear Regression)

* 데이터 점들에 직선을 맞추는 방법
* **직선 방정식**

$$
y = wx + b
$$

* $w$: 기울기(coefficient, weight)
* $b$: 절편(intercept, bias)
* 목표: 직선과 데이터 점들 간 **오차 최소화**

### 🔹 손실함수 (Loss Function)

* **MSE (Mean Squared Error, 평균제곱오차)**

$$
MSE = \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

* 실제값 $y$와 예측값 $\hat{y}$의 차이를 제곱해 평균
* 값이 작을수록 모델 설명력이 좋음

### 🔹 최적화 관점

* MSE는 **볼록 함수(convex function)** → 최소값이 유일
* 선형회귀 = “손실함수를 최소화하는 $w, b$를 찾는 문제”

### 🔹 해법

1. **해석적 해법 (Analytical Solution)** – 정규방정식

$$
w = (X^TX)^{-1}X^Ty
$$

2. **수치적 해법 (Numerical Solution)** – 경사하강법(Gradient Descent)

---

## 2. 상관관계 vs 인과관계

* **상관관계 (Correlation)**: 변수들이 함께 변하지만 원인-결과 아님

  * 예: 아이스크림 판매량 ↑ ↔ 물놀이 사고 ↑ (공통원인 = 더위)
* **인과관계 (Causation)**: 한 변수가 다른 변수에 직접 영향

  * 예: 담배 ↑ → 폐암 ↑

### 🔹 상관분석 기본 가정

1. 선형성
2. 등분산성
3. 정규성
4. 독립성

### 🔹 피어슨 상관계수

$$
r = \frac{\text{공분산}(X, Y)}{\sigma_X \sigma_Y}
$$

* 범위: $-1 \leq r \leq 1$
* +1: 완전 양의 상관
* -1: 완전 음의 상관
* 0: 관계 없음

---

## 3. 분류 모델 (Classification Model)

* **정의**: 종속변수 $y$가 **범주형/이산형 변수**
* **예시**:

  * 이메일 → 스팸/정상
  * 종양 → 악성/양성

### 🔹 이진분류 (Binary Classification)

* 출력값이 **0 또는 1**
* 가장 기본적인 분류 문제

---

## 4. 분류에서 사용하는 손실함수

### MSE의 한계

* 분류 문제에선 패널티가 약해 잘 작동하지 않음

### 🔹 크로스엔트로피 (Cross Entropy)

* **이진 분류(Binary Cross Entropy)**

$$
L = - \Big( y \log(\hat{y}) + (1-y)\log(1-\hat{y}) \Big)
$$

* 장점:

  1. 잘못된 예측에 큰 패널티
  2. 로지스틱 함수와 결합 → 미분 단순, 학습 효율 ↑

---

## 5. 다중분류 (Multiclass Classification)

* 클래스가 3개 이상일 때 사용

### 🔹 소프트맥스 (Softmax)

$$
P(y = k | x) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}
$$

* 모든 클래스 확률의 합 = 1

---

## 6. 주요 분류 알고리즘

### KNN (K-Nearest Neighbors)

* 가장 가까운 $K$개의 이웃을 보고 다수결로 분류
* 단순하지만 데이터 많으면 계산량 ↑

### 결정트리 (Decision Tree)

* 조건에 따라 데이터를 분할해 트리 구조
* **불순도(impurity)** 척도: 지니지수, 엔트로피

### 랜덤포레스트 (Random Forest)

* 여러 결정트리를 무작위 학습 → 투표로 최종 결정

### 앙상블 (Ensemble)

* 여러 모델 결합 → 성능 향상
* Bagging, Boosting, Stacking

---

## 7. 결정경계 (Decision Boundary)

* 분류 모델이 클래스를 구분하는 기준선
* 2D → 직선/곡선
* 고차원 → **초평면(hyperplane)**

---

## 8. 서포트 벡터 머신 (SVM)

* **마진을 최대화하는 초평면** 탐색
* 서포트 벡터: 경계 근처의 핵심 데이터

### 🔹 커널 트릭 (Kernel Trick)

* 데이터를 고차원으로 매핑 → 선형 분리 가능하게 변환
* 선형, 다항식, RBF 커널 등

---

# ✅ 최종 정리

* **회귀**: 연속값 예측 (MSE, 선형회귀, 경사하강법)
* **분류**: 범주값 예측 (Cross Entropy, 로지스틱 회귀, Softmax)
* **상관 vs 인과**: 관계 해석에 주의
* **결정트리·랜덤포레스트**: 불순도 기반 분류, 앙상블
* **SVM**: 마진 최대화, 커널 트릭

---

