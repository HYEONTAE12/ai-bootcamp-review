{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2675152d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📌 DataLoader 정리\n",
    "\n",
    "## 1. DataLoader란?\n",
    "\n",
    "* `torch.utils.data.DataLoader`는 **Dataset + Sampler**를 결합해서\n",
    "  → **반복 가능한 객체(iterable)**로 만들어주는 클래스.\n",
    "* 역할:\n",
    "\n",
    "  * 데이터를 **batch 단위**로 묶어줌\n",
    "  * epoch마다 **데이터 순서를 섞어줌(shuffle)**\n",
    "  * **병렬 프로세싱(num_workers)**으로 빠르게 데이터 로딩\n",
    "  * GPU 학습 시 **pin_memory**로 전송 최적화\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 주요 인자\n",
    "\n",
    "### 필수\n",
    "\n",
    "* **`dataset`**\n",
    "  어떤 데이터를 읽을지 (`TensorDataset`, `ImageFolder`, `MNIST`, 커스텀 Dataset 등)\n",
    "\n",
    "### 자주 쓰는 핵심 인자\n",
    "\n",
    "* **`batch_size`** (기본 1) → 한 번에 몇 개의 샘플을 반환할지\n",
    "* **`shuffle`** (기본 False)\n",
    "\n",
    "  * `True`: epoch마다 섞음 → **train** 데이터셋에 주로 사용\n",
    "  * `False`: 섞지 않음 → **validation/test** 데이터셋에 사용\n",
    "* **`num_workers`** (기본 0) → 데이터 로딩에 사용할 CPU 프로세스 수\n",
    "\n",
    "\n",
    "```python\n",
    "# cpu 코어 확인\n",
    "import os\n",
    "  os.cpu_count()\n",
    "\n",
    "```\n",
    "\n",
    "  * 0: 메인 프로세스 (느림, 디버깅용)\n",
    "  * > 0: 병렬 처리 (빠름, 실전용)\n",
    "* **`drop_last`** (기본 False)\n",
    "\n",
    "  * 데이터 개수가 `batch_size`로 나누어떨어지지 않을 때, 마지막 배치 버릴지 여부\n",
    "\n",
    "### 상황에 따라 중요한 인자\n",
    "\n",
    "* **`collate_fn`** → batch로 묶는 방식을 정의 (특히 NLP, variable-length 데이터 처리에 중요)\n",
    "* **`pin_memory`** → GPU 학습 시 데이터 전송 최적화 (`True` 권장)\n",
    "* **`generator`** → 셔플 시 시드 고정 (재현성 확보)\n",
    "* **`persistent_workers`** → epoch 끝나도 worker를 종료하지 않고 유지 (속도 최적화)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 동작 과정\n",
    "\n",
    "1. DataLoader는 dataset에서 **샘플 인덱스**를 가져옴 (sampler)\n",
    "2. batch_size만큼 모아서 배치(batch)를 만듦\n",
    "3. collate_fn으로 텐서 묶음으로 변환\n",
    "4. GPU 학습이면 pin_memory로 메모리 고정 후 반환\n",
    "5. epoch이 끝나면 다시 shuffle 가능\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 사용 예시\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# 데이터셋 만들기\n",
    "data = torch.arange(20).reshape(10, 2).float()\n",
    "labels = torch.arange(10)\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "# DataLoader 생성\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_size=4,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2,\n",
    "                    drop_last=False,\n",
    "                    pin_memory=True)\n",
    "\n",
    "# 반복 사용\n",
    "for epoch in range(2):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    for batch in loader:\n",
    "        x, y = batch\n",
    "        print(x, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 보통 설정하는 방식\n",
    "\n",
    "* **train loader**\n",
    "\n",
    "  ```python\n",
    "  DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "  ```\n",
    "* **validation/test loader**\n",
    "\n",
    "  ```python\n",
    "  DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=4, drop_last=False, pin_memory=True)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 핵심 요약\n",
    "\n",
    "* **Dataset → DataLoader**로 감싸야 모델 학습 루프에서 쉽게 사용 가능\n",
    "* 꼭 알아야 할 인자: `dataset`, `batch_size`, `shuffle`, `num_workers`, `drop_last`\n",
    "* 성능 최적화: `pin_memory=True`, `num_workers`를 CPU 코어 개수에 맞춰 튜닝\n",
    "\n",
    "---\n",
    "\n",
    "현태, 내가 DataLoader를 **train/valid/test로 나누어서 실제 학습 루프(`for epoch in range...`)**에 어떻게 들어가는지 예제 코드도 정리해줄까?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6f2f1",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 📌 1. `collate_fn`\n",
    "\n",
    "* 역할: **여러 샘플을 하나의 배치(batch)로 묶는 방식**을 정의.\n",
    "* 기본 동작: 리스트로 가져온 샘플들을 `torch.stack()`해서 텐서로 합쳐줌.\n",
    "* 필요할 때:\n",
    "\n",
    "  * 데이터 길이가 제각각일 때 (예: NLP 문장 길이 다름 → 패딩 필요)\n",
    "  * 배치 단위 전처리를 하고 싶을 때\n",
    "  * 커스텀 Dataset을 쓸 때 데이터 형태가 텐서가 아닐 경우\n",
    "\n",
    "👉 예시 (문장의 길이가 다를 때 패딩):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474059d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# 데이터셋 만들기\n",
    "data = torch.arange(20).reshape(10, 2).float()\n",
    "labels = torch.arange(10)\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "# DataLoader 생성\n",
    "def collate_batch(batch):\n",
    "    # batch = [샘플1, 샘플2, ...] (각 샘플은 텍스트 길이 다름)\n",
    "    texts, labels = zip(*batch)\n",
    "    # 가장 긴 문장 길이에 맞춰 패딩\n",
    "    max_len = max(len(t) for t in texts)\n",
    "    padded = [t + [0]*(max_len-len(t)) for t in texts]\n",
    "    return torch.tensor(padded), torch.tensor(labels)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=4, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a21fec",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 2. `pin_memory`\n",
    "\n",
    "* 역할: **데이터를 CUDA pinned memory(고정 메모리)**에 올려둔 뒤 GPU로 바로 전송.\n",
    "* 왜 필요해?\n",
    "\n",
    "  * 일반적으로 CPU→GPU 전송은 비동기 처리가 안 되는데,\n",
    "  * pinned memory를 쓰면 **비동기 전송**이 가능해서 속도가 빨라짐.\n",
    "* GPU 학습 시 `pin_memory=True` 권장 (특히 이미지/대규모 텐서).\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 동기(Synchronous)\n",
    "\n",
    "* CPU가 GPU로 데이터를 보낼 때,\n",
    "  **GPU가 다 받았는지 확인할 때까지 CPU가 기다림**\n",
    "* 즉, CPU와 GPU가 한 번에 하나의 일만 순서대로 처리 → 병목 가능\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 비동기(Asynchronous)\n",
    "\n",
    "* CPU가 GPU로 데이터를 보내는 “명령”만 내리고,\n",
    "  **GPU가 받는 동안 CPU는 다른 작업을 계속함**\n",
    "* CPU와 GPU가 동시에 일을 처리할 수 있음 → 속도 최적화\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 PyTorch에서\n",
    "\n",
    "* 그냥 `.to(\"cuda\")` → 동기 전송\n",
    "* `pin_memory=True` + `.to(\"cuda\", non_blocking=True)` → 비동기 전송 가능\n",
    "\n",
    "---\n",
    "\n",
    "✅ 한 줄 요약:\n",
    "동기 = CPU가 GPU 기다림\n",
    "비동기 = CPU와 GPU가 동시에 일함 (pin_memory + non_blocking 필요)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb0c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin_memory= True\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "for data, target in loader:\n",
    "    data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e717fff",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 📌 3. `generator`\n",
    "\n",
    "* 역할: 난수 생성기 지정. (`torch.Generator`)\n",
    "* 언제 쓰냐?\n",
    "\n",
    "  * `shuffle=True`일 때 데이터 순서를 섞는 난수를 제어\n",
    "  * `random_split` 등과 동일하게, **seed 고정**해서 **재현성 확보**할 때 필요\n",
    "* 예시:\n",
    "\n",
    "```python\n",
    "g = torch.Generator().manual_seed(42)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, generator=g)\n",
    "```\n",
    "\n",
    "→ 실행할 때마다 항상 같은 순서로 섞임.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d49b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator().manual_seed(42)\n",
    "g = torch.Generator().manual_seed(42)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, generator=g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861cfb9f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 📌 4. `persistent_workers`\n",
    "\n",
    "* 역할: DataLoader에서 worker 프로세스를 **epoch이 끝난 뒤에도 종료하지 않고 유지**.\n",
    "* 왜 필요해?\n",
    "\n",
    "  * 기본값(`False`) → epoch이 끝날 때마다 worker가 종료됐다가 다시 만들어짐 → overhead 발생\n",
    "  * `True` → worker 유지 → 다음 epoch에서 바로 사용 → 속도 향상\n",
    "* 조건: `num_workers > 0`일 때만 의미 있음.\n",
    "* 긴 학습에서 **성능 최적화**용으로 쓰임.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a28cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=64, num_workers=4, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4ccad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
