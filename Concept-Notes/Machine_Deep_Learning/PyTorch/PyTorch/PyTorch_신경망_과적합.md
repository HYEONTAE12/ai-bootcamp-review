
---

# 📌 과적합 (Overfitting)

## 1. 과적합이란?

* **정의**: 모델이 학습 데이터에 지나치게 맞춰져서 새로운 데이터(테스트 데이터, 실제 환경 데이터)에는 일반화가 잘 되지 않는 현상.
* **특징**

  * Train 데이터 성능은 계속 향상되지만, Validation/Test 데이터 성능은 일정 시점부터 떨어진다.
  * 너무 복잡한 모델일수록, 데이터 수가 적을수록 더 잘 발생한다.

---

## 2. 과적합이 일어나는 이유

* **모델 복잡성(유연성)**: 파라미터가 많고, 모델이 복잡할수록 더 많은 패턴을 학습 가능 → 잡음까지 학습(분산 ↑).
* **데이터 부족**: 충분한 데이터가 없으면 일반화가 어렵다.
* **불균형 데이터**: 데이터 분포가 치우쳐 있으면 특정 패턴만 과도하게 학습.
* **훈련 에폭 과다**: 너무 오래 학습하면 결국 훈련 데이터에 최적화.

---

## 3. 과적합 방지 방법

### 3.1 정규화 (Regularization)

* **개념**: 가중치에 제약을 줘서 모델 복잡성을 줄이는 방법.
* **이유**: 특정 입력/특징이 지나치게 강조되지 않도록 제어.

---

### 3.2 L1 & L2 Regularization

#### 🔹 L1 정규화 (Lasso)

* **방식**: 손실함수 + λ × ∑|w|
* **효과**:

  * 불필요한 가중치를 **0**으로 만들어 변수 선택(Feature Selection) 효과.
  * 희소한 네트워크(Sparse Network) 형성.
* **장점**: 해석 용이, 변수 제거로 모델 단순화, 일반화 성능 개선.
* **단점**: 다중공선성에 약함, 규제 값 선택 민감, Ridge보다 예측 성능 낮을 수 있음.

#### 🔹 L2 정규화 (Ridge)

* **방식**: 손실함수 + λ × ∑w²
* **효과**:

  * 모든 가중치를 조금씩 줄임 → 가중치 폭발 방지.
  * 0은 거의 되지 않음 → 희소성 부족.
* **장점**: 다중공선성에 강함, 예측 성능 안정적, 계산적으로 안정적.
* **단점**: 해석 어려움, 이상치에 약함, 규제 강도 선택에 민감.

#### 🔹 L1 + L2 (Elastic Net)

* **방식**: L1 + L2 결합.
* **효과**: L1의 변수 선택 기능 + L2의 안정성을 동시에 활용.

---

### 3.3 Dropout

* **원리**: 학습 시 뉴런을 확률 p로 비활성화(출력 0).
* **추론 시**: 모든 뉴런 사용, 단 훈련 때의 스케일을 보정하기 위해 `1/(1-p)` 배 조정.
* **장점**:

  * 특정 뉴런/경로 조합 의존성 감소.
  * 앙상블 효과(매 배치마다 다른 네트워크 학습).
* **단점**:

  * p 값이 크면 과소적합.
  * 작은 모델·작은 데이터셋에서는 효과 제한적.

---

### 3.4 Early Stopping

* **원리**: 학습 중 Validation 성능이 더 이상 개선되지 않으면 학습 조기 종료.
* **장점**: 단순하고 효과적, 과적합 방지.
* **단점**: 언제 멈출지 기준( patience ) 설정이 필요.

---

### 3.5 데이터 증강 (Data Augmentation)

* **원리**: 원본 데이터를 변형(회전, 자르기, 밝기/채도 변화 등)하여 데이터 수 인위적으로 증가.
* **예시**:

  * 이미지: 회전, 반전, 크롭, 색상 변환.
  * 텍스트: 동의어 치환, 문장 순서 변환.
  * 음성: 잡음 추가, 속도/톤 변화.
* **장점**: 다양한 데이터 학습 → 일반화 성능 증가.
* **단점**: 잘못 적용하면 의미 왜곡 가능.

---

### 3.6 모델 단순화

* 파라미터 수 줄이기 (작은 네트워크 사용).
* 특징 선택(Feature Selection)으로 중요한 변수만 사용.

---

### 3.7 교차 검증 (Cross-Validation)

* 데이터를 K개로 나누어 반복적으로 학습·검증.
* 모델이 데이터에 과도하게 치우치지 않았는지 확인 가능.

---

### 3.8 앙상블 (Ensemble)

* 여러 모델을 합쳐서 예측(배깅, 부스팅, 스태킹).
* 단일 모델의 과적합 위험을 분산.

---

## ✅ 정리

* 과적합은 **모델이 복잡하거나 데이터가 부족할 때** 발생.
* 방지 방법:

  1. 정규화 (L1/L2, Elastic Net)
  2. Dropout
  3. Early Stopping
  4. 데이터 증강
  5. 모델 단순화
  6. 교차 검증
  7. 앙상블

---


