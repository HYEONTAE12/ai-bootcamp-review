{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd272164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0ea85",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📌 PyTorch 메모리 포맷 정리\n",
    "\n",
    "## 1. 기본 개념\n",
    "\n",
    "* **메모리 포맷(memory_format)** = 텐서가 **메모리에 어떤 순서로 저장되어 있는지**를 정의\n",
    "* CNN 연산 속도 최적화에서 중요 (특히 GPU, cuDNN)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 주요 옵션\n",
    "\n",
    "### 🔹 `torch.contiguous_format`\n",
    "\n",
    "* PyTorch 기본 포맷 = **NCHW** (Batch, Channel, Height, Width)\n",
    "* 메모리에 채널 단위로 모아서 저장\n",
    "* `x.is_contiguous()` → True면 이 포맷\n",
    "\n",
    "### 🔹 `torch.channels_last`\n",
    "\n",
    "* **NHWC** (Batch, Height, Width, Channel)\n",
    "* 픽셀 단위로 RGB가 연속 저장됨\n",
    "* Conv2d에서 GPU 최적화 효과 ↑\n",
    "* 사용법:\n",
    "\n",
    "  ```python\n",
    "  x = x.to(memory_format=torch.channels_last)\n",
    "  model = model.to(memory_format=torch.channels_last)\n",
    "  ```\n",
    "\n",
    "### 🔹 `torch.channels_last_3d`\n",
    "\n",
    "* **NDHWC** (Batch, Depth, Height, Width, Channel)\n",
    "* 3D ConvNet (영상, CT/MRI 등) 최적화\n",
    "* Conv3d 연산에 효과적\n",
    "\n",
    "### 🔹 `torch.preserve_format`\n",
    "\n",
    "* `clone`, `to`, `detach` 등으로 텐서를 복사할 때\n",
    "* **입력 텐서의 메모리 포맷 그대로 유지**\n",
    "* 예: `channels_last` 입력을 그대로 복제할 때 사용\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 왜 중요한가?\n",
    "\n",
    "* CNN 연산에서는 **픽셀 단위로 채널(RGB 등)을 동시에 불러와야 함**\n",
    "* `contiguous_format(NCHW)` → 같은 픽셀의 채널 값이 메모리에 흩어져 있음 (비효율적)\n",
    "* `channels_last(NHWC)` → 같은 픽셀의 채널이 연속 저장 → **GPU가 직선으로 빠르게 읽음(coalesced access)**\n",
    "* 결과적으로 Conv 속도가 빨라지고, 특히 AMP(FP16)와 같이 쓰면 효과 극대화\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 한 줄 요약\n",
    "\n",
    "* **contiguous_format** = 기본 (NCHW)\n",
    "* **channels_last** = 2D CNN GPU 최적화 (NHWC)\n",
    "* **channels_last_3d** = 3D CNN GPU 최적화 (NDHWC)\n",
    "* **preserve_format** = 텐서 복제 시 원래 포맷 유지\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f06ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default clone stride: (150528, 1, 672, 3)\n",
      "preserve stride: (150528, 1, 672, 3)\n",
      "same format? True\n"
     ]
    }
   ],
   "source": [
    "# 입력을 channels_last로 만든 상태\n",
    "x = torch.randn(8, 3, 224, 224, device=\"cpu\").to(memory_format=torch.channels_last)\n",
    "\n",
    "# 그냥 clone() → 기본 contiguous_format으로 바뀔 수 있음\n",
    "y1 = x.clone()\n",
    "print(\"default clone stride:\", y1.stride())\n",
    "\n",
    "# preserve_format 사용 → 입력과 같은 메모리 포맷 유지\n",
    "y2 = x.clone(memory_format=torch.preserve_format)\n",
    "print(\"preserve stride:\", y2.stride())\n",
    "\n",
    "print(\"same format?\", x.stride() == y2.stride())  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea83309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
