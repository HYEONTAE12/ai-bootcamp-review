
---

# ğŸ“Œ `watch_log` ì½”ë“œ ë¦¬ë·°

## 1. í´ë˜ìŠ¤ ì´ˆê¸°í™”

```python
def __init__(self, df, scaler=None, label_encoder=None):
    self.df = df
    self.features = None
    self.labels = None
    self.scaler = scaler
    self.label_encoder = label_encoder
    self.contents_id_map = None
    self._preprocessing()
```

* `WatchLogDataset`ì„ í˜¸ì¶œí•˜ë©´ì„œ ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ë©´, í•´ë‹¹ ë°ì´í„°ê°€ ìƒì„±ìì— ë“¤ì–´ê°€ì„œ ë‚´ë¶€ ë³€ìˆ˜ê°€ ì´ˆê¸°í™”ë¨.
* `scaler`, `label_encoder`ë¥¼ **ê¸°ë³¸ê°’ None**ìœ¼ë¡œ ë‘” ì´ìœ ëŠ”:

  * ìƒˆë¡œìš´ ë°ì´í„°ì…‹ â†’ ìƒˆë¡­ê²Œ í•™ìŠµ(fit)
  * ê¸°ì¡´ ë°ì´í„°ì…‹ â†’ ì´ë¯¸ í•™ìŠµëœ ì „ì²˜ë¦¬ê¸°ë¥¼ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©
* `features`, `labels`, `contents_id_map`ì€ ì´í›„ ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì±„ì›Œì§ˆ ë³€ìˆ˜.
* `_preprocessing()`ì„ ë°”ë¡œ í˜¸ì¶œí•˜ì—¬ ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ì „ì²˜ë¦¬ê°€ ì‹¤í–‰ë¨.

---

## 2. ì „ì²˜ë¦¬ ê³¼ì •

```python
def _preprocessing(self):
    if self.label_encoder:
        self.df["content_id"] = self.label_encoder.transform(self.df["content_id"])
    else:
        self.label_encoder = LabelEncoder()
        self.df["content_id"] = self.label_encoder.fit_transform(self.df["content_id"])
```

* `label_encoder`ê°€ ì£¼ì–´ì§„ ê²½ìš° â†’ ê¸°ì¡´ ë§¤í•‘ëŒ€ë¡œ `content_id`ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜.
* ì—†ëŠ” ê²½ìš° â†’ `LabelEncoder()`ë¥¼ ìƒˆë¡œ ìƒì„±í•´ `fit_transform`ìœ¼ë¡œ í•™ìŠµ + ë³€í™˜ì„ ë™ì‹œì— ìˆ˜í–‰.
* ê²°ê³¼ì ìœ¼ë¡œ `self.df["content_id"]`ëŠ” ì •ìˆ˜í˜• ë¼ë²¨ì´ ë¨.

---

```python
self.contents_id_map = dict(enumerate(self.label_encoder.classes_))
```

* **ì—­ë§¤í•‘**ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ìƒì„±.
* `label_encoder.classes_`: `fit()` ì‹œ í•™ìŠµí•œ ê³ ìœ  í´ë˜ìŠ¤ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.
* `enumerate`ë¡œ ê° í´ë˜ìŠ¤ì— ë²ˆí˜¸ë¥¼ ë¶™ì—¬ `{ì •ìˆ˜: ì›ë˜ content_id}` í˜•íƒœë¡œ ì €ì¥.
* ì˜ˆì¸¡ ê²°ê³¼(ì •ìˆ˜)ë¥¼ ì›ë˜ ID ë¬¸ìì—´ë¡œ ë˜ëŒë¦´ ë•Œ ì‚¬ìš©.

---

```python
target_columns = ["rating", "popularity", "watch_seconds"]
self.labels = self.df["content_id"].values
features = self.df[target_columns].values
```

* `target_columns`: í•™ìŠµì— ì‚¬ìš©í•  feature ì»¬ëŸ¼ë“¤.
* `self.labels`: `content_id` ì •ìˆ˜ ë¼ë²¨.
* `features`: ì§€ì •í•œ feature ì»¬ëŸ¼ë“¤ì˜ ê°’ë§Œ ì¶”ì¶œ.

---

```python
if self.scaler:
    self.features = self.scaler.transform(features)
else:
    self.scaler = StandardScaler()
    self.features = self.scaler.fit_transform(features)
```

* `scaler`ê°€ ìˆìœ¼ë©´ í•™ìŠµ ì—†ì´ **transform**ë§Œ ìˆ˜í–‰.
* `scaler`ê°€ ì—†ìœ¼ë©´ `StandardScaler()`ë¥¼ ìƒˆë¡œ ìƒì„±í•´ `fit_transform`ìœ¼ë¡œ í•™ìŠµ + ë³€í™˜.
* í•™ìŠµëœ `scaler`ëŠ” ì €ì¥ë¼ ì´í›„ val/testì—ë„ ë™ì¼í•˜ê²Œ ì ìš©.

---

## 3. ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ

```python
def decode_content_id(self, encoded_id):
    return self.contents_id_map[encoded_id]
```

* ëª¨ë¸ ì˜ˆì¸¡ê°’(ì •ìˆ˜)ì„ ì›ë˜ ì½˜í…ì¸  ID ë¬¸ìì—´ë¡œ ë³µì›.

---

```python
@property
def features_dim(self): 
    return self.features.shape[1]

@property
def num_classes(self): 
    return len(self.label_encoder.classes_)
```

* ëª¨ë¸ ìƒì„± ì‹œ í¸ì˜ë¥¼ ìœ„í•´ ì œê³µ.
* `features_dim`: ì…ë ¥ feature ê°œìˆ˜
* `num_classes`: ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜

---

```python
def __len__(self): 
    return len(self.labels)

def __getitem__(self, idx): 
    return self.features[idx], self.labels[idx]
```

* `len(dataset)` â†’ ìƒ˜í”Œ ê°œìˆ˜ ë°˜í™˜.
* `dataset[i]` â†’ (feature, label) ìŒ ë°˜í™˜.
* íŒŒì´ì¬ ê¸°ë³¸ ì»¨ë²¤ì…˜ì„ ë”°ë¥´ë©°, ë°ì´í„°ì…‹ ê°ì²´ë¥¼ iterableí•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ.

---

## 4. ë°ì´í„°ì…‹ ì¤€ë¹„ í•¨ìˆ˜

```python
def read_dataset():
    watch_log_path = os.path.join(project_path(), "dataset", "watch_log.csv")
    return pd.read_csv(watch_log_path)
```

* `watch_log.csv` íŒŒì¼ì„ ì½ì–´ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜.
* `project_path()`ë¥¼ í†µí•´ ìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ê°€ì ¸ì™€ ì•ˆì „í•˜ê²Œ ê²½ë¡œ êµ¬ì„±.

---

```python
def split_dataset(df):
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
    train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42)
    return train_df, val_df, test_df
```

* ë°ì´í„°ì…‹ì„ **train\:val\:test = 6:2:2** ë¹„ìœ¨ë¡œ ë‚˜ëˆ”.
* `random_state` ê³ ì •ìœ¼ë¡œ ì¬í˜„ì„± ë³´ì¥.

---

```python
def get_datasets(scaler=None, label_encoder=None):
    df = read_dataset()
    train_df, val_df, test_df = split_dataset(df)

    train_dataset = WatchLogDataset(train_df, scaler, label_encoder)
    val_dataset = WatchLogDataset(val_df,
                                  scaler=train_dataset.scaler,
                                  label_encoder=train_dataset.label_encoder)
    test_dataset = WatchLogDataset(test_df,
                                   scaler=train_dataset.scaler,
                                   label_encoder=train_dataset.label_encoder)
    return train_dataset, val_dataset, test_dataset
```

* ìµœì¢… ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜.
* `train_dataset`ì—ì„œ í•™ìŠµí•œ `scaler`, `label_encoder`ë¥¼ ê·¸ëŒ€ë¡œ val/testì— ì „ë‹¬í•´ **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**.
* ê²°ê³¼: `(train_dataset, val_dataset, test_dataset)` íŠœí”Œ ë°˜í™˜.

---

# âœ… ìš”ì•½

* **`WatchLogDataset` í´ë˜ìŠ¤**ëŠ” ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ **ë¼ë²¨ ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§, feature/label ë¶„ë¦¬**ê¹Œì§€ ìë™ ìˆ˜í–‰.
* **`get_datasets` í•¨ìˆ˜**ëŠ” CSVë¥¼ ì½ì–´ train/val/testë¡œ ë‚˜ëˆ„ê³ , ë™ì¼ ì „ì²˜ë¦¬ê¸°ë¥¼ ì ìš©í•´ ë°ì´í„° ëˆ„ìˆ˜ë¥¼ ë§‰ìŒ.
* ëª¨ë¸ í•™ìŠµ/í‰ê°€ ë‹¨ê³„ì—ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•´ ì£¼ëŠ” êµ¬ì¡°.

---

