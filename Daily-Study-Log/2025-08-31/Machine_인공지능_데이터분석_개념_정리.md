
---

# 📘 인공지능 & 데이터 분석 개념 정리

오늘 강의 내용을 정리한 자료입니다.
AI, 데이터, EDA 관련 핵심 개념을 빠짐없이 담고, 실무에서 참고할 수 있도록 일부 보충 설명도 포함했습니다.

---

## 🤖 인공지능 (Artificial Intelligence)

### 🌀 기술적 특이점 (Singularity)

* AI가 인간의 도움 없이 스스로 발전 → **인류 전체 지능을 뛰어넘는 시점**

### 🎭 튜링 테스트 (Turing Test)

* 인간과 동등한 지적 능력이 있는지 판별하는 시험
* **문제점**: 기준이 모호하고 질문자 주관에 의존 → 큰 의미 없음

### 🤏 약인공지능 (Weak AI)

* **정해진 과제**만 잘 수행 (현재 대부분의 AI)

### 💡 강인공지능 (Strong AI)

* 사람처럼 **복합적 사고**로 **모든 문제 해결** 가능
* 현재는 이론적 개념에 불과

---

## 🛠 Low / High Level Functions

* **Low-level**: 하드웨어 동작, 단순·작은 작업
* **High-level**: 사람이 생각하는 기능, 복잡·큰 단위 작업

---

## 🧮 Universal Approximation Theorem

* 특정 구조의 신경망은 **적절히 학습하면 모든 함수를 근사 가능**
* → 인공신경망의 강력함을 뒷받침하는 이론

---

## 📊 데이터 종류

* **정형 데이터 (Structured)**: 테이블 형태, 수치화 가능
* **비정형 데이터 (Unstructured)**: 이미지, 텍스트, 오디오 등

---

## 🔢 변수의 종류

* **수치형 변수**: 숫자로 표현 (키, 나이, 온도)
* **범주형 변수**: 범주로 표현 (성별, 국가, 혈액형)

---

## 🖼 이미지 표현 방식

### 비트맵 (Bitmap)

* RGB(0\~255) 벡터로 색상 표현
* 해상도만큼 겹쳐서 전체 이미지를 구성

---

## 🌟 좋은 데이터란?

* **좋은 성능의 모델**을 학습할 수 있는 데이터
* 양보다 **품질**이 중요

---

## ⚠️ 데이터 노이즈 (Noise)

노이즈가 많으면 모델이 함수 정의를 제대로 못하고 성능 저하 발생

**대표 사례**

* ❌ 결측치: NaN, null, NA → 측정/저장/파싱 문제
* ❌ 이상치: 이론 범위 밖 값, 분포에서 크게 벗어난 값
* ❌ 중복 샘플: 같은 데이터 반복
* ❌ 틀린 라벨: 라벨링 실수
* ❌ 도메인 외 샘플: 모델 범위 밖 입력

---

## 🔇 Silent Failure (조용한 실패)

* 학습은 정상처럼 보이지만 → **결과는 전혀 쓸 수 없음**

---

## 🧾 모호한 데이터 처리

* **구체적 기준 필수**
* 예: "a"는 동그라미가 정확해야 함 / 여러 글자가 동시에 인식되면 폐기

---

## 🔍 EDA (Exploratory Data Analysis)

탐색적 데이터 분석 = **데이터 이해 → 문제 정의 → 모델링 초석**

### 목적

1. 데이터 명확한 이해
2. 정확한 문제 정의 & 모델링
3. 가설 세우고 검증

### 절차

1. **기본 정보 파악**

   * 샘플 수, 변수 개수·종류
   * 데이터 타입, 값의 범위, 범주 확인
   * 비정형 변수 여부
2. **노이즈 탐지** (결측치, 불가능 값)
3. **이상치 탐지** (박스플롯: 최소, Q1, Q3, 최대)
4. **피쳐 스케일 조정**

   * 표준화: 평균 0, 분산 1
   * 정규화: 최소 0, 최대 1
5. 랜덤 샘플 추출 → 패턴 파악
6. 변수 통계량·분포 확인
7. 변수 간 관계 분석 (상관계수, 시각화)

---

## 🎯 데이터셋 편향 (Bias)

* 특정 클래스/샘플이 매우 적거나 없음
* 해결: **데이터 수집 개선, 리샘플링(SMOTE 등)**

---

## 👀 정성 평가 (Qualitative Evaluation)

* 샘플을 직접 눈으로 확인
* 지루해 보이지만 데이터 이해도를 높이는 **가장 쉬운 방법**

---

## 🔗 공선성 (Collinearity) & 다중 공선성 (Multicollinearity)

* **공선성**: 한 변수가 다른 변수와 거의 동일
* **다중 공선성**: 한 변수가 여러 변수의 조합으로 표현됨
* 문제 발생 가능 → 변수 선택 / 차원 축소 필요 (PCA 등)

---

## 📏 표준화 vs 정규화

| 구분                        | 정의         | 결과                   |
| ------------------------- | ---------- | -------------------- |
| **표준화 (Standardization)** | 평균=0, 분산=1 | 데이터 분포를 정규화된 형태로 변환  |
| **정규화 (Normalization)**   | 최소=0, 최대=1 | 데이터 범위를 \[0,1]로 스케일링 |

---

# ✅ 결론

EDA는 단순한 데이터 탐색이 아니라,
👉 **데이터 이해 → 문제 정의 → 모델링 설계**로 이어지는 **출발점**이다.

좋은 데이터와 올바른 탐색 과정을 거쳐야 좋은 AI 모델을 만들 수 있다.

---

