
---

# 🧠 CNN (Convolutional Neural Network, 합성곱 신경망)

## 1. 등장 배경

* 기존 **완전 연결 신경망(FCN)**은 입력 데이터의 모든 픽셀을 하나의 벡터로 펼쳐 학습 → **공간적 정보 손실** 발생

  * 예: 이미지의 가까운 픽셀은 서로 연관성이 크고, 먼 픽셀은 상대적으로 연관성이 적음
  * 하지만 완전 연결 방식은 이 관계를 무시
* 따라서 **공간적 구조(Spatial Information)를 유지**하며 학습할 수 있는 구조 필요 → **CNN의 등장**

---

## 2. 합성곱 연산 (Convolution Operation)

### 기본 원리

* 입력 데이터에 **필터(커널)**를 적용하여 **슬라이딩 윈도우 방식**으로 스캔
* 입력과 필터에서 대응되는 원소끼리 **곱하고 더함**
* 결과값을 모아 **피처맵(Feature Map)** 생성

### 특징

* **필터의 채널 수 = 입력 데이터의 채널 수**
  (예: RGB 이미지 → 필터도 R/G/B 각각에 적용 후 합산)
* 합성곱 후에는 보통 **1개의 피처맵**이 생성됨
  (다수의 필터 사용 시 여러 개의 피처맵 생성 → **깊이 방향 확장**)

---

## 3. 합성곱 연산의 파라미터들

### ✅ 스트라이드 (Stride)

* 필터가 이동하는 간격
* 값이 클수록 피처맵 크기 감소
* **Downsampling 효과** 존재

### ✅ 패딩 (Padding)

* 합성곱 시 입력 데이터 가장자리에 값을 채움
* 목적:

  1. 피처맵 크기 축소 방지
  2. 가장자리 정보 손실 방지
* 방식:

  * **Valid Padding**: 패딩 없음 → 출력 크기 작아짐
  * **Same Padding**: 출력 크기를 입력과 같게 유지

---

## 4. 풀링 연산 (Pooling Operation)

### 개념

* **가로/세로 크기를 줄이는 연산**
* 합성곱 레이어의 출력(피처맵)을 다운샘플링
* 주요 역할:

  * 파라미터 수 감소 → 학습 효율 ↑
  * 과적합 방지
  * 계산량 감소
  * 잡음에 대한 강건성 확보

### 방식

* **슬라이딩 윈도우 방식** (주로 2×2, 3×3 사용)

#### 1) 최대 풀링 (Max Pooling)

* 윈도우 내 **최댓값 선택**
* 중요한 특징만 남기고 싶을 때 유용
* CNN에서 가장 널리 사용

#### 2) 평균 풀링 (Average Pooling)

* 윈도우 내 **평균값 계산**
* 이미지의 **전반적 구조 보존**에 적합
* 최근에는 잘 쓰이지 않고, 주로 최대 풀링이 표준

---

## 5. CNN의 장점

* **지역적 특징(Local Feature) 학습**
  → 이미지 내 특정 패턴(모서리, 곡선 등)을 효과적으로 탐지
* **파라미터 수 감소**
  → FCN 대비 훨씬 효율적 (필터 공유)
* **위치 불변성(Translation Invariance)**
  → 물체가 이미지 내 위치를 달리해도 잘 인식

---

## 6. 전체 구조 개요

CNN은 보통 다음과 같은 구조를 가짐:

1. **입력 레이어** (이미지 데이터)
2. **합성곱 레이어(Conv Layer)** → 특징 추출
3. **풀링 레이어(Pooling Layer)** → 크기 축소 및 요약
4. (필요 시 반복)
5. **완전 연결 레이어(FC Layer)** → 분류 or 회귀 수행
6. **출력 레이어(Softmax, Sigmoid 등)**

---

👉 정리하면, CNN은 **공간 정보를 보존하면서 특징을 추출**하는 데 강력한 구조이고, 합성곱과 풀링을 통해 효율적으로 학습할 수 있게 설계된 네트워크예요.

---
