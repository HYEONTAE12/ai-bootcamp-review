{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e94c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686cd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨Ïò¨ Îïå, ÌïÑÏöîÌïú Î≥ÄÌôò(transform)ÏùÑ Ï†ïÏùòÌï©ÎãàÎã§.\n",
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(), # ÌÖêÏÑú ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5341df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = './MNIST_DATASET'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=True, download=True) # train dataset Îã§Ïö¥Î°úÎìú\n",
    "test_dataset = torchvision.datasets.MNIST(download_root, transform=mnist_transform, train=False, download=True) # test dataset Îã§Ïö¥Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a41a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset Í∞úÏàò :  48000\n",
      "Validation dataset Í∞úÏàò :  12000\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÏÖãÏùÑ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÏÖãÍ≥º Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÏÖãÏúºÎ°ú Î∂ÑÎ¶¨Ìï©ÎãàÎã§.\n",
    "total_size = len(train_dataset)\n",
    "train_num, valid_num = int(total_size * 0.8), int(total_size * 0.2) # 8 : 2 = train : valid\n",
    "print(\"Train dataset Í∞úÏàò : \", train_num)\n",
    "print(\"Validation dataset Í∞úÏàò : \", valid_num)\n",
    "train_dataset,valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num]) # train - valid set ÎÇòÎàÑÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dce1fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d21d3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(LightningModule):\n",
    "    def __init__(self, num_classes, dropout_ratio, lr = 0.001):\n",
    "        super().__init__()\n",
    "        self.learning_rate = lr\n",
    "        self.accuracy = torchmetrics.Accuracy(task = 'multiclass', num_classes = num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),  # [BATCH_SIZE, 1, 28, 28] -> [BATCH_SIZE, 16, 24, 24]\n",
    "            nn.ReLU(),  # ReLU ÌôúÏÑ±Ìôî Ìï®Ïàò Ï†ÅÏö©\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [BATCH_SIZE, 16, 24, 24] -> [BATCH_SIZE, 32, 20, 20]\n",
    "            nn.ReLU(),  # ReLU ÌôúÏÑ±Ìôî Ìï®Ïàò Ï†ÅÏö©\n",
    "            nn.MaxPool2d(kernel_size=2), # [BATCH_SIZE, 32, 20, 20] -> [BATCH_SIZE, 32, 10, 10]\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [BATCH_SIZE, 32, 10, 10] -> [BATCH_SIZE, 64, 6, 6]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # ÌÅ¨Í∏∞Î•º 1/2Î°ú Ï§ÑÏûÖÎãàÎã§. [BATCH_SIZE, 64, 6, 6] -> [BATCH_SIZE, 64, 3, 3]\n",
    "            nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Linear(64*3*3, self.num_classes) # [BATCH_SIZE, 64*3*3] -> [BATCH_SIZE, num_classes]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x) # self.layerÏóê Ï†ïÏùòÌïú SequentialÏùò Ïó∞ÏÇ∞ÏùÑ Ï∞®Î°ÄÎåÄÎ°ú Îã§ Ïã§ÌñâÌï©ÎãàÎã§. [BATCH_SIZE, 64, 3, 3]\n",
    "        out = out.view(x.size(0), -1)  # [BATCH_SIZE, 64*3*3]\n",
    "        pred = self.fc_layer(out) # [BATCH_SIZE, num_classes]\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.accuracy(outputs, labels)\n",
    "        self.log('train_loss', loss, on_step = False , on_epoch= True, logger=True)\n",
    "        self.log('train_acc', acc, on_step = False , on_epoch= True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.accuracy(outputs, labels)\n",
    "\n",
    "        self.log('valid_loss', loss, on_step = False , on_epoch= True, logger=True)\n",
    "        self.log('valid_acc', acc, on_step = False , on_epoch= True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.accuracy(outputs, labels)\n",
    "\n",
    "        self.log('test_loss', loss, on_step= False, on_epoch = True , logger= True)\n",
    "        self.log('test_acc', acc, on_step= False, on_epoch = True , logger= True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        _, pred = torch.max(outputs, dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccaecea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\USER\\.conda\\envs\\pytorch_test\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | accuracy  | MulticlassAccuracy | 0      | train\n",
      "1 | criterion | CrossEntropyLoss   | 0      | train\n",
      "2 | layer     | Sequential         | 64.5 K | train\n",
      "3 | fc_layer  | Linear             | 5.8 K  | train\n",
      "---------------------------------------------------------\n",
      "70.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.3 K    Total params\n",
      "0.281     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b6b6ef888b4f0296590fd2ca2d51db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\.conda\\envs\\pytorch_test\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\USER\\.conda\\envs\\pytorch_test\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e25eea1ad4c4567a0e62129b175cc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f014986bfa4240a62ce252d9e4287a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved. New best score: 0.058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1fd373b4a4428897a6cd115bf81aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69238abd79874770aae9ea2b0bb1b974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90e536f6a99422b832dead4731d6147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675eedbc554a4a1e813c99557a325ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16f13f04d1744eba0b983b15ad84370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18241b2e9094d21b62d0b0263ee56db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6d26a971c54e5c99f1bfe4a283668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_loss did not improve in the last 3 records. Best score: 0.027. Signaling Trainer to stop.\n",
      "c:\\Users\\USER\\.conda\\envs\\pytorch_test\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec5d67fd36d400a9cf22dd17fe060ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "       Test metric             DataLoader 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "        test_acc            0.9934999942779541\n",
      "        test_loss           0.02021963894367218\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.02021963894367218, 'test_acc': 0.9934999942779541}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier(num_classes= 10, dropout_ratio = 0.2)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'valid_loss', mode = 'min', verbose = True)\n",
    "tensor_logger = TensorBoardLogger(save_dir=\"./tensor_logger\", name= 'test')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "            accelerator=\"cpu\",\n",
    "            max_epochs= 100,\n",
    "            callbacks = [early_stopping],\n",
    "            logger = tensor_logger\n",
    "\n",
    "    )\n",
    "\n",
    "trainer.fit(model, train_dataloader, valid_dataloader)\n",
    "trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0bb70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8516), started 0:08:59 ago. (Use '!kill 8516' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3eb13b9046685257\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3eb13b9046685257\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IPython ÌôòÍ≤ΩÏóêÏÑú tensorboard ÌôïÏû• Í∏∞Îä•ÏùÑ Î°úÎìúÌïòÎäî Ïó≠Ìï†ÏùÑ Ìï©ÎãàÎã§.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# ./runs/tutorial ÏúÑÏπòÏóê Ï†ÄÏû•Îêú Î°úÍ∑∏Î•º ÏúÑÏπòÎ°ú tensorboardÎ•º Ïã§ÌñâÌï©ÎãàÎã§.\n",
    "%tensorboard --logdir ./tensor_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "712dcaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3dbefe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# torchvision ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ CIFAR10 Îç∞Ïù¥ÌÑ∞ ÏÖãÏùÑ Î∂àÎü¨ÏòµÎãàÎã§.\n",
    "download_root = './CIFAR10_DATASET'\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(download_root, transform=cifar10_transform, train=True, download=True) # train dataset Îã§Ïö¥Î°úÎìú\n",
    "test_dataset = torchvision.datasets.CIFAR10(download_root, transform=cifar10_transform, train=False, download=True) # test dataset Îã§Ïö¥Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "471e331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset Í∞úÏàò :  40000\n",
      "Validation dataset Í∞úÏàò :  10000\n",
      "Test dataset Í∞úÏàò : 10000\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÏÖãÏùÑ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÏÖãÍ≥º Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÏÖãÏúºÎ°ú Î∂ÑÎ¶¨Ìï©ÎãàÎã§.\n",
    "total_size = len(train_dataset)\n",
    "train_num, valid_num = int(total_size * 0.8), int(total_size * 0.2) # 8 : 2 = train : valid\n",
    "print(\"Train dataset Í∞úÏàò : \", train_num)\n",
    "print(\"Validation dataset Í∞úÏàò : \", valid_num)\n",
    "print(\"Test dataset Í∞úÏàò :\", len(test_dataset))\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num]) # train - valid set ÎÇòÎàÑÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba732a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f9752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_29228\\280872993.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path = 'configs', config_name = 'config')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa12e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.learning_rate = cfg.optimizer.lr\n",
    "        self.accuracy = torchmetrics.Accuracy(task= 'multiclass', num_classes = cfg.model.model.num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = cfg.optimizer\n",
    "        self.scheduler = cfg.scheduler\n",
    "\n",
    "        self.num_classes = cfg.model.model.num_classes\n",
    "        self.dropout_ratio = cfg.model.model.dropout_ratio\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),  # [BATCH_SIZE, 1, 28, 28] -> [BATCH_SIZE, 16, 24, 24]\n",
    "            nn.ReLU(),  # ReLU ÌôúÏÑ±Ìôî Ìï®Ïàò Ï†ÅÏö©\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [BATCH_SIZE, 16, 24, 24] -> [BATCH_SIZE, 32, 20, 20]\n",
    "            nn.ReLU(),  # ReLU ÌôúÏÑ±Ìôî Ìï®Ïàò Ï†ÅÏö©\n",
    "            nn.MaxPool2d(kernel_size=2), # [BATCH_SIZE, 32, 20, 20] -> [BATCH_SIZE, 32, 10, 10]\n",
    "            nn.Dropout(self.dropout_ratio),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [BATCH_SIZE, 32, 10, 10] -> [BATCH_SIZE, 64, 6, 6]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # ÌÅ¨Í∏∞Î•º 1/2Î°ú Ï§ÑÏûÖÎãàÎã§. [BATCH_SIZE, 64, 6, 6] -> [BATCH_SIZE, 64, 3, 3]\n",
    "            nn.Dropout(self.dropout_ratio),\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Linear(1024, self.num_classes)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc05d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.accuracy = torchmetrics.Accuracy(task = 'multiclass', num_classes = cfg.model.model.num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = cfg.optimizer\n",
    "        self.scheduler = cfg.scheduler\n",
    "\n",
    "        self.model = instantiate(cfg.model.model)\n",
    "        self.softmax = nn.Softmax(dim= 1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = instantiate(self.optimizer, self.parameters())\n",
    "        scheduler = instantiate(self.scheduler, optimizer)\n",
    "        \n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f38839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_29228\\3771103185.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path = 'configs', config_name = 'config')\n"
     ]
    }
   ],
   "source": [
    "@hydra.main(config_path = 'configs', config_name = 'config')\n",
    "def main(cfg):\n",
    "\n",
    "    train_dataset = instantiate(cfg.data.train_dataset)\n",
    "\n",
    "    test_dataset = instantiate(cfg.data.test_dataset)\n",
    "\n",
    "    train_num, valid_num = int(len(train_dataset) * (1 - cfg.data.dataloader.valid_split)), int(len(train_dataset) * cfg.data.dataloader.valid_split)\n",
    "    print(\"Train dataset Í∞úÏàò : \", train_num)\n",
    "    print(\"Validation dataset Í∞úÏàò : \", valid_num)\n",
    "    print(\"Test dataset Í∞úÏàò : \", len(test_dataset))\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num])\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size = cfg.data.dataloader.batch_size, shuffle= True)\n",
    "    \n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size = cfg.data.dataloader.batch_size, shuffle= False)\n",
    "    \n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size = cfg.data.dataloader.batch_size, shuffle= False)\n",
    "\n",
    "    if cfg.model.model.model_name == 'simple_cnn':\n",
    "        model = SimpleCNN(cfg)\n",
    "    else:\n",
    "        model = ResNet(cfg)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor = cfg.callback.monitor,\n",
    "                                   mode = cfg.callback.mode, patience = cfg.callback.patience)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval= cfg.callback.logging_interval)\n",
    "\n",
    "    logger = TensorBoardLogger(**cfg.logger)\n",
    "\n",
    "    trainer = Trainer(\n",
    "                    **cfg.trainer,\n",
    "                    callback = [early_stopping, lr_monitor],\n",
    "                    logger = logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    trainer.test(model, test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
