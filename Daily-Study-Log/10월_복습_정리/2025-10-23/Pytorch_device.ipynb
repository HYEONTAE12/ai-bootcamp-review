{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abd6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f586bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\.conda\\envs\\pytorch_test\\lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())      # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ (True/False)\n",
    "print(torch.cuda.device_count())      # ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜\n",
    "print(torch.cuda.get_device_name(0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53f2a9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ“Œ PyTorch Device ì •ë¦¬\n",
    "\n",
    "## 1. ê¸°ë³¸ ê°œë…\n",
    "\n",
    "* **device**: í…ì„œ/ëª¨ë¸ì´ ì–´ë””(CPU/GPU/ê°€ì†ê¸°)ì— ì˜¬ë¼ê°ˆì§€ ì •í•˜ëŠ” ê°ì²´\n",
    "* í˜•íƒœ: `torch.device(type, index)`\n",
    "\n",
    "  * **type**: `\"cpu\"`, `\"cuda\"`, `\"mps\"`, `\"xpu\"`, `\"rocm\"`\n",
    "  * **index**: ê°™ì€ íƒ€ì… ì¥ì¹˜ê°€ ì—¬ëŸ¬ ê°œì¼ ë•Œ ë²ˆí˜¸ (`cuda:0`, `cuda:1` â€¦)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ì£¼ìš” device ìœ í˜•\n",
    "\n",
    "| ìœ í˜•       | ëŒ€ìƒ í•˜ë“œì›¨ì–´           | ë¹„ê³               |\n",
    "| -------- | ----------------- | --------------- |\n",
    "| **cpu**  | CPU               | í•­ìƒ ì‚¬ìš© ê°€ëŠ¥        |\n",
    "| **cuda** | NVIDIA GPU        | ê°€ì¥ ë§ì´ ì“°ì„        |\n",
    "| **mps**  | Apple Silicon GPU | ë§¥ë¶ M1/M2ìš©       |\n",
    "| **xpu**  | Intel GPU         | Intel oneAPI ê¸°ë°˜ |\n",
    "| **rocm** | AMD GPU           | AMD GPU ì§€ì›      |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. device ì¸ë±ìŠ¤ (index)\n",
    "\n",
    "* GPUê°€ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°:\n",
    "\n",
    "  * `cuda:0` â†’ 0ë²ˆ GPU\n",
    "  * `cuda:1` â†’ 1ë²ˆ GPU â€¦\n",
    "* í™•ì¸ë²•:\n",
    "\n",
    "  ```python\n",
    "    print(\"count:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(i, props.name, props.total_memory // (1024**2), \"MB\")\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ë‚œìˆ˜ ìƒì„± ì‹œì—ë„ device ì§€ì •í•˜ëŠ” ì´ìœ \n",
    "\n",
    "* `torch.randn((2,3), device=\"cuda:0\")`\n",
    "  â†’ í…ì„œê°€ ë°”ë¡œ GPUì— ìƒì„±ë¨\n",
    "* ë§Œì•½ CPUì—ì„œ ë§Œë“  ë’¤ `.to(\"cuda:0\")` í•˜ë©´ **CPU ë©”ëª¨ë¦¬ + GPU ë³µì‚¬ ì˜¤ë²„í—¤ë“œ** ë°œìƒ\n",
    "* ì¦‰, **ë©”ëª¨ë¦¬/ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ì²˜ìŒë¶€í„° deviceë¥¼ ì§€ì •í•˜ëŠ” ê²Œ ê°€ì¥ íš¨ìœ¨ì **\n",
    "\n",
    "---\n",
    "\n",
    "## 5. `torch.device(n)` ì •ìˆ˜ë§Œ ì“°ëŠ” ê²½ìš°\n",
    "\n",
    "* `torch.device(0)` â†’ í˜„ì¬ ê¸°ë³¸ ê°€ì†ê¸°ê°€ **cuda**ë¼ë©´ `cuda:0`ìœ¼ë¡œ í•´ì„ë¨\n",
    "* `torch.device(1)` â†’ ê¸°ë³¸ ê°€ì†ê¸°ê°€ **xpu**ë¼ë©´ `xpu:1`ì´ ë  ìˆ˜ ìˆìŒ\n",
    "* ê°€ì†ê¸°ê°€ ì—†ìœ¼ë©´ **RuntimeError ë°œìƒ**\n",
    "* **ì£¼ì˜**: ë§ˆì§€ë§‰ì— ë§Œë“  deviceì™€ëŠ” ë¬´ê´€í•¨\n",
    "\n",
    "---\n",
    "\n",
    "## 6. CUDA_VISIBLE_DEVICES\n",
    "\n",
    "* í™˜ê²½ë³€ìˆ˜: **ì–´ë–¤ GPUë¥¼ ë³´ì—¬ì¤„ì§€, ì–´ë–¤ ìˆœì„œë¡œ ë³´ì—¬ì¤„ì§€** ì œí•œ/ì¬ë§¤í•‘\n",
    "* ì˜ˆ:\n",
    "\n",
    "  ```bash\n",
    "  export CUDA_VISIBLE_DEVICES=2,3\n",
    "  ```\n",
    "\n",
    "  â†’ PyTorch ì…ì¥ì—ì„œ\n",
    "\n",
    "  * `cuda:0` = ì‹¤ì œ ë¬¼ë¦¬ GPU 2\n",
    "  * `cuda:1` = ì‹¤ì œ ë¬¼ë¦¬ GPU 3\n",
    "* ëª©ì : **ì„œë²„ì—ì„œ ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ì“¸ ë•Œ ì¶©ëŒ ë°©ì§€**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… ìµœì¢… ìš”ì•½\n",
    "\n",
    "* **device = í…ì„œ/ëª¨ë¸ì´ ì˜¬ë¼ê°ˆ ìœ„ì¹˜**\n",
    "* ìì£¼ ì“°ëŠ” ê±´ `\"cpu\"`, `\"cuda:i\"`\n",
    "* í•™ìŠµí•  ë• ë‚œìˆ˜/í…ì„œë¥¼ ë°”ë¡œ GPUì— ìƒì„±í•´ì•¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì \n",
    "* `torch.device(n)`ì€ ê¸°ë³¸ accelerator ê¸°ì¤€ìœ¼ë¡œë§Œ ë™ì‘ â†’ ì•ˆì „í•˜ê²Œ ì“°ë ¤ë©´ í•­ìƒ `\"cuda:0\"` ì‹ìœ¼ë¡œ ëª…ì‹œ\n",
    "* ì„œë²„ í™˜ê²½ì—ì„œëŠ” `CUDA_VISIBLE_DEVICES`ë¡œ GPU ì¶©ëŒì„ ë°©ì§€í•˜ê³  ê´€ë¦¬\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‘‰ í˜„íƒœë‹˜, ì›í•˜ë©´ ì œê°€ ì´ ë‚´ìš©ì„ **ê·¸ë¦¼(íë¦„ë„)**ì²˜ëŸ¼ ì •ë¦¬í•´ì„œ â€œë¡œì»¬ PC (GPU 1ê°œ)â€ vs â€œì„œë²„ (GPU ì—¬ëŸ¬ ê°œ)â€ ìƒí™©ì„ ë¹„êµí•´ë“œë¦´ê¹Œìš”?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cpu\n",
      "mps\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch.device() : device ê°ì²´ë¥¼ ë§Œë“ ë‹¤\n",
    "# ì‹¤ì œë¡œ deviceê°€ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì´ ê°ì²´ëŠ” ë§Œë“¤ì–´ì§„ë‹¤.\n",
    "# ì¦‰, CUDA GPUê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ì—ëŸ¬ëŠ” ì•ˆ ë‚˜ê³ , ê·¸ í…ì„œë¥¼ ì‹¤ì œë¡œ ë§Œë“¤ ë•Œ ì—ëŸ¬ ë°œìƒ\n",
    "\n",
    "print(torch.device('cuda:0'))\n",
    "\n",
    "\n",
    "print(torch.device('cpu'))\n",
    "\n",
    "\n",
    "print(torch.device('mps'))\n",
    "\n",
    "\n",
    "print(torch.device('cuda'))  # implicit index is the \"current device index\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b7116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¥ì¹˜ ìœ í˜• ë° ì¥ì¹˜ ìˆœì„œ \n",
    "\n",
    "# NVIDIA GPU 0ë²ˆì„ ê°€ë¦¬í‚¤ëŠ” device ê°ì²´ ìƒì„±\n",
    "torch.device('cuda', 0)\n",
    "\n",
    "# Apple Silicon(M1/M2) GPUë¥¼ ê°€ë¦¬í‚¤ëŠ” device ê°ì²´ ìƒì„±\n",
    "torch.device('mps', 0)\n",
    "\n",
    "# CPUë¥¼ ê°€ë¦¬í‚¤ëŠ” device ê°ì²´ \n",
    "# CPUëŠ” ì¸ë±ìŠ¤ ì˜ë¯¸ê°€ ì—†ì–´ì„œ 0ì„ ìƒëµí•´ë„ë¨\n",
    "torch.device('cpu', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with torch.device :  ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ â†’ ê¸°ë³¸ deviceë¥¼ cuda:0ë¡œ ì„¤ì •\n",
    "# r = torch.randn(2,3) : tensor rì„ ìƒì„±í•˜ë©´ ìë™ìœ¼ë¡œ cuda:0 ì— ì˜¬ë¼ê°\n",
    "# r.device : rì´ ì‹¤ì œë¡œ ìˆëŠ” ì¥ì¹˜ í™•ì¸\n",
    "\n",
    "with torch.device('cuda:0'):       \n",
    "    r = torch.randn(2, 3)         \n",
    "r.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda0ì€ torch.deviceì˜ ê°ì²´\n",
    "# device= ì¸ìë¡œ ê°ì²´ë¡œ ì „ë‹¬í•˜ë©´ í•´ë‹¹ ì¥ì¹˜ì— ë°”ë¡œ í…ì„œê°€ ìƒì„±ëœë‹¤.\n",
    "cuda0 = torch.device('cuda:0')\n",
    "torch.randn((2,3), device=cuda0)\n",
    "\n",
    "# ë¬¸ìì—´ë¡œ ëŒ€ì²´ ê°€ëŠ¥\n",
    "x = torch.randn((2,3), device='cuda:0')\n",
    "print(x.device)   # cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ deviceë¥¼ í•œ ë²ˆë§Œ ì§€ì •\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ì´í›„ ëª¨ë“  í…ì„œ/ëª¨ë¸ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©\n",
    "x = torch.randn((2,3), device=device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51dff5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ğŸ“Œ PyTorchì—ì„œ ìŠ¤ì¹¼ë¼ ìë™ ì „ì†¡ ì •ë¦¬\n",
    "\n",
    "* **ì¼ë°˜ ê·œì¹™**: CPU â†” GPU ê°„ í…ì„œëŠ” **ìë™ ì´ë™ ì•ˆ ë¨**, ë°˜ë“œì‹œ `.to(device)` í•„ìš”\n",
    "* **ì˜ˆì™¸**: **ìŠ¤ì¹¼ë¼ í…ì„œ (dim()==0)** ëŠ” CPU â†’ GPUë¡œ ì—°ì‚° ì‹œ ìë™ ì „ì†¡ë¨\n",
    "* **GPU â†’ CPU ìë™ ì „ì†¡ì€ ì—†ìŒ**\n",
    "* **ì‹¤ë¬´ í™œìš©**: ì†ì‹¤ê°’(loss), ì‘ì€ ìƒìˆ˜(ì˜ˆ: `+ 1.0`, `* 0.5`) ê°™ì€ ê²½ìš°ì—ë§Œ í¸ì˜ìƒ ì“°ì¼ ë¿, ëŒ€ë¶€ë¶„ì€ `.to(device)`ë¡œ ë§ì¶”ëŠ” ê²Œ ì•ˆì „\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‘‰ í•œ ì¤„ ìš”ì•½:\n",
    "**PyTorchëŠ” ìŠ¤ì¹¼ë¼ë§Œ CPUâ†’GPU ìë™ ì „ì†¡ í—ˆìš©, ë‚˜ë¨¸ì§€ëŠ” ì „ë¶€ ìˆ˜ë™ìœ¼ë¡œ `.to(device)` í•´ì•¼ í•œë‹¤.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7768044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1) CPU ìŠ¤ì¹¼ë¼ + GPU ë²¡í„° (ìë™ ì „ì†¡ O)\n",
    "a = torch.ones(())            # CPU scalar\n",
    "b = torch.ones(3).cuda()      # GPU vector\n",
    "print((a + b).device)         # cuda:0\n",
    "\n",
    "# 2) GPU ìŠ¤ì¹¼ë¼ + CPU ë²¡í„° (ìë™ ì „ì†¡ X â†’ ì—ëŸ¬)\n",
    "try:\n",
    "    a = torch.ones(()).cuda()   # GPU scalar\n",
    "    b = torch.ones(3)           # CPU vector\n",
    "    print((a + b).device)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
