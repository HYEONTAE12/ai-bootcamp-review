

---

#  ML 경진대회에서 얻은 인사이트 정리

## 1. 데이터 분할과 일반화 성능

* **문제**: 로컬에서는 train/valid 성능이 안정적이나, test에서는 예측이 계속 빗나감.
* **가설**: valid는 랜덤/과거 섞임, test는 최근(2023-07\~09) 국면. → 분포 차이로 valid 성능이 과대평가됨.
* **확인**: 랜덤 홀드아웃을 사용하다 보니 일반화 성능이 떨어짐.
* **대응**: `TimeSeriesSplit`을 사용, 과거 데이터로 미래를 검증.
* **결과**: RMSE가 로컬 6\~7천대 → 2만대로 점프. → 일반화 성능 저하 확인.
* **결론**: **시간 순서를 고려하지 않고 학습하면 미래 예측 성능이 왜곡된다.**

---

## 2. 이상치와 분포 왜곡

* **문제**: 일부 feature(전용면적, 층, 전체동수 등)가 정규분포를 따르지 않고 이상치가 많음.
* **가설**: 이상치를 제거하면 성능 향상.
* **확인**: 시각화(histplot, boxplot)로 분포를 확인 → 대부분 좌측 치우침 + 우측 꼬리.
* **대응**: drop 대신 log 변환 선택. 변환 후 분포가 중앙으로 모임.
* **결과**: LGBM 단일 모델 기준 유의미한 성능 개선 없음. → LGBM이 이상치에 강건함 확인.
* **결론**: **트리 모델은 값 자체보다 임계값으로 구간을 나누기 때문에 이상치 영향이 제한적이다.**

---

## 3. 범주형 변수와 과적합

* **문제**: 카테고리형 변수(동, 구, 아파트명 등)가 importance에서 과도하게 높음 → 과적합 의심.
* **가설**: 인코딩 방식 문제.
* **확인**: 전부 라벨 인코딩 상태 확인.
* **대응**:

  * 동/아파트명 → 타겟 인코딩 + 스무딩 (m=1, 5, 10, 50, 100, 200 sweep)
  * 구 → 원-핫 인코딩 (종류 25개)
  * 도로명 → 빈도 인코딩 (카테고리 수 9천+).
* **결과**: 스무딩만으로 importance 영향력 억제 실패 → 오히려 성능 저하.
  → 동, 아파트명 feature drop 후 성능 개선 (RMSE 24000 → 17300).
* **결론**: **집값에 직접적으로 중요한 feature라도 과적합을 유발하면 과감히 제거해야 한다.**

---

## 4. 외부 거시경제 변수 추가

* **문제**: 원본 데이터만으로는 성능 한계.
* **가설**: 금리, GDP, CPI, 거래량 같은 거시경제 feature 추가 시 성능 향상.
* **확인**:

  * 한국은행·KOSIS에서 데이터 수집 (2007\~2023).
  * 금리: 2023 동결 → 상수 처리 위험. → 구간화(cut) 후 저·중·고금리로 나눔.
  * 거래량 × 금리 조합 파생변수 생성.
  * GDP: 분기 데이터 → 월별 선형 보간(50→56 → 52, 54, 56).
* **대응**: heatmap 분석 → 월별 GDP와 CPI의 상관관계 99%. → GDP drop.
* **결과**:

  * 로컬 제출: RMSE 17370 → 17300 (소폭 개선).
  * 최종 보드: RMSE **13000대** → 대폭 개선.
* **결론**: **실제 사회에서 집값에 영향을 주는 변수들은 단기 효과는 약해도 장기적으로 일반화 성능을 높인다.**

---

## 5. 연도별 표본 불균형

* **문제**: 연도별 데이터 불균형 심각 (2014~~2020 집중, 2022~~2023 희소).
* **가설**: 연도별 가중치 보정 시 예측 성능 향상.
* **확인**: 계약년별 count 집계 후 중앙값 기준으로 가중치 계산:

  $$
  \text{가중치} = \frac{\text{전체 연도 샘플 수 중앙값}}{\text{해당 연도 샘플 수}}
  $$
* **대응**: 샘플 수 많은 연도 → 작은 가중치 / 샘플 적은 연도 → 큰 가중치.
* **결과**:

  * 로컬 RMSE 17300 → 15700 개선.
  * 최종 보드 RMSE **11063** 달성.
* **결론**: **데이터 불균형 시 가중치 학습은 강력한 성능 개선을 가져온다.**

---

# 🎯 종합 인사이트

1. **시간축 분할 필수** – 미래 예측 문제에서는 랜덤 분할은 금물.
2. **이상치 처리** – 트리 모델은 log 변환의 효과가 제한적.
3. **범주형 변수** – 정보량은 크지만 과적합 리스크도 크다. 필요 시 제거가 답.
4. **거시경제 변수** – 단기엔 무의미해도 장기 예측 성능에 강력한 기여.
5. **데이터 불균형 보정** – 연도별 가중치로 모델 학습 안정성 확보 가능.

---

정리하면, **단순히 모델 파라미터 튜닝만으로는 한계가 있었고, 데이터 분할 방식·외부 변수 추가·불균형 보정 같은 “데이터 중심 전략”이 최종 성능 개선의 핵심**

---


