
---

# 📝 이가람 멘토님의 경진대회 회고 정리

## 1. 대회의 의미와 경험

* 단순히 점수 경쟁을 넘어, **머신러닝 문제 해결 프로세스를 처음부터 끝까지 경험**하는 것이 핵심 목적이었다.
* 데이터 전처리 → 모델 선택 → 학습 및 평가 전 과정을 직접 구동하며, 정형 데이터 기반 ML 프로젝트 경험을 쌓는 기회였다.

---

## 2. 단계별로 잡았어야 할 방향

### (1) 베이스라인 파이프라인 경험

* 새로운 방법을 고민하기 전에, **우선 베이스라인 코드와 데이터 흐름을 그대로 돌려보는 것**이 필요하다.
* 데이터 분포 확인(히스토그램, 상관계수, 박스플롯)과 코드 구조 이해 → baseline 점수 제출까지 빠르게 경험하는 것이 중요하다.

### (2) 간단한 하이퍼파라미터 튜닝

* 학습률, 트리 수, 깊이 같은 핵심 파라미터를 조정해 성능을 소폭 개선했어야 했다.
* 이 과정은 과적합 여부, 학습 속도 등을 감각적으로 익히는 데 의미가 있다.

### (3) 데이터 분석을 통한 개선

* EDA를 통해 데이터의 경향성과 문제점을 더 깊이 확인했어야 했다.

  * 결측치/이상치 탐색
  * 변수 변환 및 파생변수 생성
  * 시계열적 특성을 반영할지 여부 판단
* 단순히 변수를 추가하는 게 아니라 **문제 정의와 일치하는 데이터 처리**가 우선이었다.

### (4) 반복적 개선

* 위 과정을 반복하면서 점차 성능을 끌어올리는 것이 필요했다.
* 단순히 한 번에 많은 변수를 추가하기보다는 **작은 단위 실험 → 결과 검증 → 기록**의 루프가 중요했다.

---

## 3. 추가적으로 고려했어야 할 점

* **모델 다양성**: LightGBM만 고집하지 말고, Linear Regression, XGBoost, CatBoost, TabNet 등도 탐색했어야 했다.
* **하이퍼파라미터 최적화**: WandB, Optuna 같은 툴을 적극 활용해 자동화했으면 더 효율적이었음.
* **평가 전략**: 시계열 split 같은 문제 특화 분할 방식을 더 신중하게 써야 했다.
* **리소스 관리**: 시간/자원 제약 속에서 우선순위를 정하고 집중하는 전략이 필요했다.
* **협업과 기록**: 팀원 간 커뮤니케이션과 실험 기록(노션, 깃허브, WandB)이 부족했다면 개선해야 한다.
* **가설 기반 실험**: 무작정 변수 추가가 아니라, 가설 → 실험 → 결과 → 피드백 → 새로운 가설 순환이 필요하다.

---

## 4. 멘토님의 핵심 메시지

* 대회는 단순히 점수를 높이는 게임이 아니라, **ML 문제 해결 전체 프로세스를 익히는 연습장**이다.
* “선택과 집중” 전략, 반복적 실험, 기록 관리가 앞으로 실무나 다음 대회에서 더 큰 차이를 만들 것이다.

---

👉 요약하면, 이번 대회에서 더 좋았을 방향은
**Baseline 확보 → 작은 단위 실험 반복 → 기록 관리 → 다양한 모델 탐색 → 문제 정의에 맞는 데이터 처리와 분할 전략 적용**


---

